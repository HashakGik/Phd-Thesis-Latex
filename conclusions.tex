Neuro-symbolic Artificial Intelligence is a research area with significant challenges hindering its practical applicability. On one hand, integrating symbolic representations into continuous setting presents challenges which are exacerbated when their semantics must be learned from observations, in a way which is both aligned with human intuition and beneficial to downstream tasks. There is strong evidence that the role of time in human learning is beneficial for the development of meaningful concepts, however the temporal dimension is a challenging and often overlooked aspect of Machine Learning with untapped potential.
%
On the other hand, evaluating progress in Neuro-symbolic integration is limited by uneven and scattered evaluation frameworks which make fair comparisons difficult.
%
Starting from an analysis of these two challenges, in this thesis we propose a (i.) \textit{Comprehensive Taxonomy for Benchmarks in Neuro-symbolic Artificial Intelligence}, covering also the temporal dimension, and two novel benchmarking frameworks for (ii.) \textit{Curriculum-based Abstract Visual Reasoning} and (iii.) \textit{Learning and Reasoning over Time}.

We argue that performance evaluation is insufficient for learning and reasoning settings and that auxiliary metrics are needed for a broader characterization. Acknowledging the existence of trade-offs between desiderata, we strongly encourage benchmark designers to clearly state evaluation objectives and expected outcomes, to guide practioners towards fair empirical comparison.
Our proposed taxonomy allows for quick retrieval of tasks of interest and it can ease the design of new benchmarks coherent with respect to their declared goals.
We hope that broad adoption of these guidelines by the community can help transitioning towards a less fragmented landscape in Neuro-Symbolic Artificial Intelligence.

\textsc{KANDY}, our Abstract Visual Reasoning benchmarking framework allows to generate hierarchical compositions of geometric shapes, guided by First-order Logic rules, and disclosed progressively to learning agents in a curriculum-based setting. \textsc{KANDY} can be exploited for multiple tasks, including Curriculum-guided Inductive Reasoning and Concept Discovery over Time. Our experiences on \textsc{KANDY} validate its challenging nature, confirming its usefulness as a benchmarking tool for Neuro-symbolic Artificial Intelligence. Our experiences with a novel symbolic representation learning approach based on Concept Embedding Models and Contrastive Learning on \textsc{KANDY} hint toward a positive effect of progressive disclosure over time in Unsupervised Concept Discovery.

\textsc{LTLZinc}, our Relational Learning and Reasoning over Time benchmarking framework, allows to build benchmarks for a wide range of learning and reasoning tasks over time, that can benefit the Temporal Reasoning and Continual Learning communities, by means of a unified formalism. Tasks relevant for the Temporal Reasoning community include Sequence Classification with Background Knowledge, Temporal Distant Supervision and Constraint Induction over Time. The Continual Learning community can benefit from \textsc{LTLZinc} capabilities in generating complex temporal behaviors which generalize the traditional Incremental Learning settings to a broader class of problems, and the possibility of explicitly formalizing such temporal behaviors by means of Temporal Logic. Our Neuro-symbolic experiences on \textsc{LTLZinc} explore the setting of Sequence Classification with Background Knowledge, highlighting a significant increase in complexity, compared to existing benchmarks, due to its relational nature, and opening the possibility of Approximate Formal Verification of Safety-critical Systems by Neuro-symbolic means.
Our Continual Learning experiences on \textsc{LTLZinc} point toward the need of redefining experimental settings and mitigation strategies for catastrophic forgetting which exploit background knowledge on task progression more effectively.

\section{Contributions}
We hereby summarize the main contributions of this thesis.

\paragraph{Symbolic Representation Learning.} Representations for symbolic systems must be discrete and their integration with gradient-based (continuous) methods is challenging. In this thesis we have sampled existing approaches from the literature and identified \textit{desirable properties} and \textit{challenges} which are common across methods attempting to learn symbolic representations. We have also implemented a method to \textit{learn concepts unsupervisedly by exploiting time}, addressing some of the challenges.

\paragraph{Benchmarks in Neuro-symbolic Artificial Intelligence.} The evaluation landscape in Neuro-symbolic Artificial Intelligence is scattered and fair comparison is hindered by a lack of unified frameworks. In this thesis we proposed a \textit{taxonomy} to better categorize existing benchmarks and guide the development of novel evaluation frameworks covering under-represented areas. We proposed \textsc{KANDY}, a \textit{novel benchmarking framework for Abstract Visual Reasoning over time}, covering multiple First-order reasoning tasks from multiple reasoning directions, with the help of a curriculum-based progression. The challenging nature of \textsc{KANDY} is confirmed by inductive reasoning experiments on \textit{symbolic methods and Vision Language Models}, while the beneficial effect of time is confirmed by \textit{Continual Learning} experiments with Neural Networks.
We also proposed \textsc{LTLZinc}, a \textit{novel benchmarking framework for relational-temporal Learning and Reasoning}, capable of covering temporal reasoning and Continual Learning tasks with a \textit{unified formalism and generation framework}. The challenging nature of \textsc{LTLZinc} is confirmed by extensive \textit{Sequence Classification with background knowledge} experiments with Neural Networks and Neuro-symbolic methods for temporal reasoning.

\paragraph{Learning over Time.} Time is a powerful prior for learning, however exploiting it introduces significant challenges in the learning process. In this thesis we experimented on the effect of curriculum learning on Neural Networks, by exploring \textit{inductive reasoning} and \textit{unsupervised concept discovery} on top of \textsc{KANDY}. We have also exploited the \textsc{LTLZinc} framework to introduce the novel setting of \textit{Continual Learning with Background Knowledge} and experimented on \textit{Class-Continual tasks}.

\paragraph{Reasoning over Time.} Reasoning over time is a broad setting characterized by the need of integrating relational capabilities and memory. In this setting, the \textsc{LTLZinc} framework can be exploited to produce datasets from compact specifications. We experimented on Neuro-symbolic \textit{Sequence Classification with Background Knowledge} and \textit{Approximate Formal Verification of Traces} by means of a modular architecture.

\section{Final Remarks}
\paragraph{Limitations.} The limited computational resources available for this thesis affected the quality of results, limiting the size of explored hyper-parameter spaces, the size of generated datasets and the overall training budget available for each experiment, both in terms of model size and optimization steps. We only scratched the surface of the interaction between Vision Language Models and Learning and Reasoning over Time, which is a direction requiring further exploration. The effect of Neuro-symbolic frameworks on \textsc{KANDY} has not been yet explored. Both \textsc{KANDY} and \textsc{LTLZinc} rely on exponential generation steps which can limit their applicability to limited size datasets and the evaluation of Neuro-symbolic methods under low-data regimes.


\paragraph{Open Research Directions.} Many research directions remain to be explored in the future. The proposed evaluation frameworks can be further refined to increase their expressivity and benchmarking capabilities. \textsc{KANDY} can be further extended to complex perceptual stimuli and additional compositional operators, its generation engine can be extended to probabilistic logic to allow the evaluation of the effects of uncertainty in background knowledge, and concept-dependency graphs, or competence-based heuristics~\cite{toborek2025beyond}, can be exploited to automatize curriculum design. \textsc{LTLZinc} can be improved in terms of scalability, to allow longer sequences, possibly enabling infinite online generation for Lifelong Learning with Background Knowledge, and its potential for the evaluation of Continual Learning with Background Knowledge can be further explored by means of more challenging tasks.
%
From a ``foundational'' perspective, this thesis opens to the possibility of exploring novel quantitative approaches to evaluate the goodness of learned symbolic representations, the exploration of novel tasks which can be expressed within the \textsc{KANDY} and \textsc{LTLZinc} frameworks, but have not been covered by this work (e.g., Constraint Induction over Time and Hierarchical Symbolic Representation Learning), and the introduction of novel Continual Learning strategies, capable of effectively exploiting background knowledge to counteract catastrophic forgetting in a targeted fashion.
%
Finally, from an ``applicative'' perspective, there is the need for significant improvements in Approximate Safety Verification by Neuro-symbolic means, before \textsc{LTLZinc} can be beneficial to a broader community.