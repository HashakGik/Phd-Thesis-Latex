\chapter{Knowledge Bases for \textsc{KANDY-Induction} Experiments}\label{app:kandyaleph}

\section{Natural Encoding - Medium size}
The following is the background knowledge used for rejection sampling during curricula generation. It allows to compactly define every task with at most 6 predicates.
The natural mid-size ({\small\textsc{Nat-Mid}}) background knowledge used in ILP experiments is built from this one, by removing domain-definition predicates (e.g., \texttt{color(red)}) in order to reduce the search space.
$\ $\\

\begin{minted}{prolog}
color(red).
color(green).
color(blue).
color(cyan).
color(magenta).
color(yellow).

shape(triangle).
shape(circle).
shape(square).

size(small).
size(large).

non_diag(stack).
non_diag(side_by_side).
non_diag(stack_reduce_bb).
non_diag(side_by_side_reduce_bb).
non_diag(grid).

diag(diag_ul_lr).
diag(diag_ll_ur).

quadrant_ul(quadrant_ul).
quadrant_ur(quadrant_ur).
quadrant_ll(quadrant_ll).
quadrant_lr(quadrant_lr).

quadrant(quadrant_ul).
quadrant(quadrant_ur).
quadrant(quadrant_ll).
quadrant(quadrant_lr).

quadrant_or_center(in).
quadrant_or_center(X) :- quadrant(X).

non_random(X) :- diag(X).
non_random(X) :- non_diag(X).
non_random(X) :- quadrant(X).
any_composition(X) :- non_random(X).
any_composition(random).


line(X) :- non_diag(X), X \= grid.
line(X) :- diag(X).

house(C) :- extract_op_and_chld(C, stack, [C1, C2]), 
extract_shape(C1, triangle), 
extract_shape(C2, square), 
same_size(_, [C1, C2]).
car(C) :- extract_op_and_chld(C, side_by_side, [C1, C2]), 
extract_shape(C1, circle), 
extract_shape(C2, circle), 
same_size(_, [C1, C2]), 
same_color(_, [C1, C2]).
tower(C) :- extract_op_and_chld(C, stack, L), 
same_shape(square, L), 
same_size(_, L), 
length(L, N), N >= 2, N =< 3.
wagon(C) :- extract_op_and_chld(C, side_by_side, L), 
same_shape(square, L), 
same_size(_, L), 
length(L, N), N >= 2, N =< 3.
traffic_light(C) :- extract_op_and_chld(C, stack, [C1, C2, C3]), 
same_shape(circle, [C1, C2, C3]), 
same_size(_, [C1, C2, C3]), 
extract_color(C1, red),
extract_color(C2, yellow),
extract_color(C3, green).
named_object(house).
named_object(car).
named_object(tower).
named_object(wagon).
named_object(traffic_light).
is_named_object(C, house) :- house(C).
is_named_object(C, car) :- car(C).
is_named_object(C, tower) :- tower(C).
is_named_object(C, wagon) :- wagon(C).
is_named_object(C, traffic_light) :- traffic_light(C).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Natural-mid-size background knowledge starts here:

shape_props(T, SH, CO, SZ) :- atom(T), 
term_string(T, S), 
split_string(S, "_", "", L),
L = [SH, CO, SZ].
extract_shape(T, SH) :- shape_props(T, SH1, _, _), 
term_string(SH, SH1), shape(SH).
extract_color(T, CO) :- shape_props(T, _, CO1, _), 
term_string(CO, CO1), color(CO).
extract_size(T, SZ) :- shape_props(T, _, _, SZ1), 
term_string(SZ, SZ1), size(SZ).

exists_shape(SH, [H|_]) :- extract_shape(H, SH).
exists_shape(SH, [_|T]) :- exists_shape(SH, T).

same_shape(SH, [H]) :- extract_shape(H, SH).
same_shape(SH, [H|T]) :- extract_shape(H, SH), same_shape(SH, T).

exists_color(CO, [H|_]) :- extract_color(H, CO).
exists_color(CO, [_|T]) :- exists_color(CO, T).

same_color(CO, [H]) :- extract_color(H, CO).
same_color(CO, [H|T]) :- extract_color(H, CO), same_color(CO, T).

exists_size(SZ, [H|_]) :- extract_size(H, SZ).
exists_size(SZ, [_|T]) :- exists_size(SZ, T).

same_size(SZ, [H]) :- extract_size(H, SZ).
same_size(SZ, [H|T]) :- extract_size(H, SZ), same_size(SZ, T).

contains(C, X) :- extract_children(C, L), member(X, L).

recursive_contains(C, X) :- contains(C, X), atom(X).
recursive_contains(C, X) :- contains(C, C1), 
recursive_contains(C1, X).


recursive_contains2(C, X, 0) :- contains(C, X), functor(C, _, 1).
recursive_contains2(C, X, I) :- contains(C, C1), 
recursive_contains2(C1, X, J), 
I is J + 1.

contains_composition(C, COMP) :- 
extract_operator(C, COMP).
contains_composition(C, COMP) :- 
recursive_contains2(C, C1, _),
extract_operator(C1, COMP).

contains_composition_depth(C, COMP, 0) :- extract_operator(C, COMP).
contains_composition_depth(C, COMP, I) :- recursive_contains2(C, C1, J), 
extract_operator(C1, COMP), I is J + 1.

extract_operator(C, COMP) :- functor(C, COMP, 1).
extract_children(C, L) :- functor(C, _, 1), arg(1, C, L).
extract_op_and_chld(C, COMP, L) :- functor(C, COMP, 1), arg(1, C, L).

same_attribute(L) :- same_shape(_, L).
same_attribute(L) :- same_color(_, L).
same_attribute(L) :- same_size(_, L).

same_non_size(L) :- same_shape(_, L).
same_non_size(L) :- same_color(_, L).

all_same(H, [H]).
all_same(H, [H|T]) :- all_same(H, T).


expand2([A, B], A, B).
expand4([A, B, C, D], A, B, C, D).
expand8([A, B, C, D, E, F, G, H], A, B, C, D, E, F, G, H).
expand9([A, B, C, D, E, F, G, H, I], A, B, C, D, E, F, G, H, I).
odd(N) :- N mod 2 =:= 1.
even(N) :- N mod 2 =:= 0.


first([H|_],H).

last([H], H).
last([_|T],X):- last(T, X).


prepend(X, L, [X|L]).
droplast([_], []).
droplast([H|T], [H|T2]):- droplast(T, T2).

middle([_|T], T2):- droplast(T, T2).
getmiddle(L, X) :- length(L, N), odd(N), N1 is div(N, 2),
nth0(N1, L, X).
dropmiddle(L, L1) :- getmiddle(L, X), delete(L, X, L1).


less_eq(N, N1) :- N =< N1.
less(N, N1) :- N < N1.
greater(N, N1) :- N > N1.

same(X, Y) :- X = Y.
different(X, Y) :- X \= Y.

% USEFUL BUILT-IN PREDICATES:
% atom(X)
% reverse(L1, L2)
% length(L, N)
% delete(L, X, L1)
% nth0(N, L, X)
% member(X, L)
	
\end{minted}
%\end{lstlisting}

\section{Natural Encoding - Minimal Size}

The following is the natural minimal ({\small\textsc{Nat-Min}}) background knowledge used in ILP experiments.
$\ $\\

%\begin{lstlisting}
\begin{minted}{prolog}
shape_props(T, SH, CO, SZ) :- atom(T), 
term_string(T, S), 
split_string(S, "_", "", L), 
L = [SH, CO, SZ].
extract_shape(T, SH) :- shape_props(T, SH1, _, _), 
term_string(SH, SH1), shape(SH).
extract_color(T, CO) :- shape_props(T, _, CO1, _), 
term_string(CO, CO1), color(CO).
extract_size(T, SZ) :- shape_props(T, _, _, SZ1), 
term_string(SZ, SZ1), size(SZ).

exists_shape(SH, [H|_]) :- extract_shape(H, SH).
exists_shape(SH, [_|T]) :- exists_shape(SH, T).

same_shape(SH, [H]) :- extract_shape(H, SH).
same_shape(SH, [H|T]) :- extract_shape(H, SH), same_shape(SH, T).

exists_color(CO, [H|_]) :- extract_color(H, CO).
exists_color(CO, [_|T]) :- exists_color(CO, T).

same_color(CO, [H]) :- extract_color(H, CO).
same_color(CO, [H|T]) :- extract_color(H, CO), same_color(CO, T).

exists_size(SZ, [H|_]) :- extract_size(H, SZ).
exists_size(SZ, [_|T]) :- exists_size(SZ, T).

same_size(SZ, [H]) :- extract_size(H, SZ).
same_size(SZ, [H|T]) :- extract_size(H, SZ), same_size(SZ, T).

contains(C, X) :- extract_children(C, L), member(X, L).

recursive_contains(C, X) :- contains(C, X), atom(X).
recursive_contains(C, X) :- contains(C, C1), 
recursive_contains(C1, X).

extract_operator(C, COMP) :- functor(C, COMP, 1).
extract_children(C, L) :- functor(C, _, 1), arg(1, C, L).
extract_op_and_chld(C, COMP, L) :- functor(C, COMP, 1), arg(1, C, L).


% USEFUL BUILT-IN PREDICATES:
% atom(X)
% reverse(L1, L2)
% length(L, N)
	
\end{minted}
%\end{lstlisting}

\section{Natural Encoding - Large Size}
The following cheat predicates were used the large background knowledge experiments. As search space is significantly increased, these did not prove to be beneficial for ILP experiments.
$\ $\\

%\begin{lstlisting}
\begin{minted}{prolog}
% CHEAT PREDICATES FOR KANDY-INDUCTION-1 CURRICULUM:

symmetric_list(L) :- reverse(L, L).

house(C) :- extract_op_and_chld(C, stack, [C1, C2]), 
extract_shape(C1, triangle), 
extract_shape(C2, square), same_size(_, [C1, C2]).
car(C) :- extract_op_and_chld(C, side_by_side, [C1, C2]), 
extract_shape(C1, circle),
extract_shape(C2, circle), same_size(_, [C1, C2]), 
same_color(_, [C1, C2]).
tower(C) :- extract_op_and_chld(C, stack, L), same_shape(square, L), 
same_size(_, L), length(L, N), 
N >= 2, N =< 3.
wagon(C) :- extract_op_and_chld(C, side_by_side, L), 
same_shape(square, L), 
same_size(_, L), length(L, N), 
N >= 2, N =< 3.
traffic_light(C) :- extract_op_and_chld(C, stack, [C1, C2, C3]), 
same_shape(circle, [C1, C2, C3]), 
same_size(_, [C1, C2, C3]), extract_color(C1, red), 
extract_color(C2, yellow), extract_color(C3, green).
named_object(house).
named_object(car).
named_object(tower).
named_object(wagon).
named_object(traffic_light).
is_named_object(C, house) :- house(C).
is_named_object(C, car) :- car(C).
is_named_object(C, tower) :- tower(C).
is_named_object(C, wagon) :- wagon(C).
is_named_object(C, traffic_light) :- traffic_light(C).

% CHEAT PREDICATES FOR KANDY-INDUCTION-2 CURRICULUM:
forall_shared_shape(C, SH) :- forall(contains(C, C1), 
(contains(C1, C2), extract_shape(C2, SH))).
forall_shared_color(C, CO) :- forall(contains(C, C1), 
(contains(C1, C2), extract_color(C2, CO))).
forall_shared_named_obj(C, X) :- forall(contains(C, C1), 
(contains(C1, C2), is_named_object(C2, X))).

pseudo_palindrome([]).
pseudo_palindrome([_]).
pseudo_palindrome(L) :- middle(L,M),pseudo_palindrome(M),
last(L,A),first(L,B), same_shape(_, [A,B]).
pseudo_palindrome(L) :- middle(L,M),pseudo_palindrome(M),
last(L,A), first(L,B), 
same_color(_, [A,B]).

pseudo_palindrome2([]).
pseudo_palindrome2([_]).
pseudo_palindrome2(L) :- middle(L,M),pseudo_palindrome2(M),
last(L,A),first(L,B), 
same_shape(_, [A,B]).
pseudo_palindrome2(L) :- middle(L,M),pseudo_palindrome2(M),
last(L,A), first(L,B), 
same_color(_, [A,B]).
pseudo_palindrome2(L) :- middle(L,M),pseudo_palindrome2(M),
last(L,C1), first(L,C2), 
is_named_object(C1, X), is_named_object(C2, X).
	
\end{minted}
%\end{lstlisting}

\section{Differences between Pointer and Natural Encodings}
Background knowledge for pointer ({\sc\small Ptr}) and natural ({\sc\small Nat}) encodings  present only few differences. Most notably, the \texttt{contains/2} predicate is implemented differently:
$\ $\\

%\begin{lstlisting}
\begin{minted}{prolog}
% pointer encoding:
contains(C, X) :- defined_as(C, _, L), member(X, L).

% natural encoding:
contains(C, X) :- extract_children(C, L), member(X, L).

extract_operator(C, COMP) :- functor(C, COMP, 1).
extract_children(C, L) :- functor(C, _, 1), arg(1, C, L).
extract_op_and_chld(C, COMP, L) :- functor(C, COMP, 1), 
arg(1, C, L).
\end{minted}
%\end{lstlisting}
$\ $\\

\noindent The other difference concerns sample representation:
$\ $\\
%\begin{lstlisting}
\begin{minted}{prolog}
% generated object (Python's dictionary of lists):
% {'in': 
%   [
%     {'grid': 
%       [
%         {'shape': 'circle', 'color': 'red', 'size': 'small'}, 
%         {'shape': 'square', 'color': 'red', 'size': 'large'},
%         {'shape': 'square', 'color': 'red', 'size': 'small'}
%       ]
%     }
%   ]
% }
	
% natural encoding (example file):
valid(in([grid([circle_red_small, square_red_large, square_red_small])])).


% pointer encoding (background knowledge):
defined_as(c000000, in, [c000001]).
defined_as(c000001, grid, 
[circle_red_small, square_red_large, square_red_small]).
sample_is(s00001, c000000).

% pointer encoding (example file):
valid(s00001).
\end{minted}
%\end{lstlisting}

\section{Ground Truth Rules}\label{app:kandyalephgt}
We report the ground truth Prolog rules that support each tasks in the curricula we released with \textsc{KANDY-Induction}.

\paragraph{\textsc{KANDY-Induction-1}.}

%\begin{lstlisting}
\begin{minted}{prolog}
	% task 0:
	valid(C) :- contains(C, C1), extract_shape(C1, triangle).
	
	% task 1:
	valid(C) :- contains(C, C1), extract_shape(C1, square).
	
	% task 2:
	valid(C) :- contains(C, C1), extract_shape(C1, circle).
	
	% task 3:
	valid(C) :- contains(C, C1), extract_color(C1, red).
	
	% task 4:
	valid(C) :- contains(C, C1), extract_color(C1, green).
	
	% task 5:
	valid(C) :- contains(C, C1), extract_color(C1, blue).
	
	% task 6:
	valid(C) :- contains(C, C1), extract_color(C1, cyan).
	
	% task 7:
	valid(C) :- contains(C, C1), extract_color(C1, magenta).
	
	% task 8:
	valid(C) :- contains(C, C1), extract_color(C1, yellow).
	
	% task 9:
	valid(C) :- extract_children(C, L), last(L, C1), 
	extract_shape(C1, triangle), extract_color(C1, red).
	
	% task 10:
	valid(C) :- extract_children(C, L), last(L, C1), 
	extract_shape(C1, triangle), extract_color(C1, red).
	
	% task 11:
	valid(C) :- extract_children(C, L), last(L, C1), 
	member(C2, L), extract_shape(C1, triangle), 
	extract_color(C1, red), extract_shape(C2, circle).
	
	% task 12:
	valid(C) :- extract_children(C, L), last(L, C1), 
	member(C2, L), extract_shape(C1, triangle), 
	extract_color(C1, red), extract_color(C2, blue).
	
	% task 13:
	valid(C) :- recursive_contains(C, C1), 
	recursive_contains(C, C2), 
	same_color(_, [C1, C2]), extract_shape(C1, triangle), 
	extract_shape(C2, square).
	
	% task 14:
	valid(C) :- extract_children(C, L), reverse(L, L).
	
	% task 15:
	valid(C) :- contains(C, C1), house(C1).
	
	% task 16:
	valid(C) :- contains(C, C1), car(C1).
	
	% task 17:
	valid(C) :- contains(C, C1), tower(C1).
	
	% task 18:
	valid(C) :- contains(C, C1), wagon(C1).
	
	% task 19:
	valid(C) :- contains(C, C1), traffic_light(C1).
	
\end{minted}
%\end{lstlisting}

\paragraph{\textsc{KANDY-Induction-1}.}


%\begin{lstlisting}
\begin{minted}{prolog}
	% task 0:
	valid(C) :- contains(C, C1), extract_children(C1, L), 
	length(L, 2), same_color(_, L).
	
	% task 1:
	valid(C) :- contains(C, C1), extract_children(C1, L), 
	length(L, 2), same_shape(_, L).
	
	% task 2:
	valid(C) :- contains(C, C1), extract_children(C1, L), 
	length(L, 3), same_color(_, L).
	
	% task 3:
	valid(C) :- contains(C, C1), extract_children(C1, L), 
	length(L, 3), same_shape(_, L).
	
	% task 4:
	valid(C) :- contains(C, C1), house(C1).
	
	% task 5:
	valid(C) :- contains(C, C1), car(C1).
	
	% task 6:
	valid(C) :- contains(C, C1), tower(C1).
	
	% task 7:
	valid(C) :- contains(C, C1), wagon(C1).
	
	% task 8:
	valid(C) :- contains(C, C1), traffic_light(C1).
	
	% task 9:
	valid(C) :- shape(SH), 
	forall(contains(C, C1), 
	(contains(C1, C2), extract_shape(C2, SH))).
	
	% task 10:
	valid(C) :- color(CO), 
	forall(contains(C, C1), 
	(contains(C1, C2), extract_color(C2, CO))).
	
	% task 11:
	valid(C) :- named_object(X), 
	forall(contains(C, C1), 
	(contains(C1, C2), is_named_object(C2, X))).
	
	% task 12:
	valid(C) :- extract_children(C, L), reverse(L, L).
	
	% task 13:
	pseudo_palindrome([]).
	pseudo_palindrome([_]).
	pseudo_palindrome(L) :- middle(L,M), pseudo_palindrome(M),
	last(L,A), first(L,B), 
	same_shape(_, [A,B]).
	pseudo_palindrome(L) :- middle(L,M), pseudo_palindrome(M), 
	last(L,A), first(L,B), 
	same_color(_, [A,B]).
	valid(C) :- extract_children(C, L), pseudo_palindrome(L).
	
	% task 14:
	pseudo_palindrome2([]).
	pseudo_palindrome2([_]).
	pseudo_palindrome2(L) :- middle(L,M), pseudo_palindrome2(M),
	last(L,A), first(L,B), 
	same_shape(_, [A,B]).
	pseudo_palindrome2(L) :- middle(L,M), pseudo_palindrome2(M),
	last(L,A), first(L,B), 
	same_color(_, [A,B]).
	pseudo_palindrome2(L) :- middle(L,M), pseudo_palindrome2(M),
	last(L,C1), first(L,C2), 
	is_named_object(C1, X), is_named_object(C2, X).
	valid(C) :- extract_children(C, L), pseudo_palindrome2(L).
	
	% task 15:
	valid(C) :- extract_children(C, L), length(L, N), 
	odd(N), same_color(_, L).
	valid(C) :- extract_children(C, L), length(L, N), 
	even(N), same_shape(_, L).
	
	% task 16:
	tmp(C) :- contains(C, C1), is_named_object(C1, traffic_light).
	tmp2(C) :- contains(C, C2), is_named_object(C2, house).
	
	valid(C) :- contains(C, C1), is_named_object(C1, traffic_light), 
	contains(C, C2), is_named_object(C2, car).
	valid(C) :- contains(C, C1), is_named_object(C1, house), 
	contains(C, C2), is_named_object(C2, tower).
	valid(C) :- not(tmp(C)), not(tmp2(C)).
	
	% task 17:
	tmp(C) :- contains(C, C1), is_named_object(C1, traffic_light).
	tmp2(C) :- contains(C, C2), is_named_object(C2, house).
	
	valid1(C) :- contains(C, C1), is_named_object(C1, traffic_light), 
	contains(C, C2), is_named_object(C2, car).
	valid1(C) :- contains(C, C1), is_named_object(C1, house), 
	contains(C, C2), is_named_object(C2, tower).
	valid1(C) :- not(tmp(C)), not(tmp2(C)).
	
	valid(C) :- forall(contains(C, C1), valid1(C1)).
\end{minted}
%\end{lstlisting}