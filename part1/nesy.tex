\chapter{Neuro-Symbolic Artificial Intelligence}
\label{chap:nesyintro}

This chapter introduces relevant literature and notions of Neuro-symbolic Artificial Intelligence, relevant throughout the thesis.

\section{Neuro-Symbolic Integration}
The main challenge of Neuro-Symbolic integration~\cite{besold2021neural} consists in providing an interface between two components: learning by means of Neural Networks, which requires representations in a continuous space, and reasoning, which often benefits from discrete representations of symbols.
A popular approach for the integration of logic knowledge, known as the model-theoretic approach~\cite{marra2024statistical}, is to relax truth assignments, in a way which extends Boolean algebra in a continuous and differentiable space.

Logic Tensor Networks (LTNs)~\cite{badreddine2022logic} produce a continuous relaxation of logic formulae by means of fuzzy logic, which are then used as layers for neural computation.
%Fuzzy logic~\cite{badreddine2022logic} extends interpretations in the continuous range $[0, 1]$ and replaces Boolean conjunction with a t-norm.\footnote{In propositional logic, every other operator is constructed by exploiting the definition $\neg \texttt{p} \doteq 1 - p$ and equivalence axioms, for fuzzy first order logic systems, additional components are required.} 
The obtained expressions are equivalent to the original Boolean formula at boundary values, but allow differentiability by means of a progressive transition between truth values, which can constrain the learning procedure~\cite{gnecco2015foundations,melacci2021domain}. Different choices of t-norms are possible, each characterized by different advantages and drawbacks. Although empirically useful for many applications, there are both theoretical and experimental evidences demonstrating a general unsuitability of fuzzy-based relaxations for learning in a differentiable setting~\cite{van2022analyzing}.

An alternative framework for model-theoretic Neuro-Symbolic integration, overcoming some issues with differentiable fuzzy logics~\cite{van2022analyzing}, is based on probabilistic inference~\cite{xu2018semantic, manhaeve2018deepproblog, winters2022deepstochlog}. In this framework, with strong theoretical and computational foundations in Statistical and Relational Artificial Intelligence (Star-AI)~\cite{raedt2016statistical}, Boolean propositions are interpreted as Bernoulli random variables and logic connectives as set operators.
While in the case of fully independent random variables, the probabilistic interpretation and the product t-norm\footnote{$\texttt{p} \wedge \texttt{q} \doteq p \cdot q, \texttt{p} \vee \texttt{q} \doteq p + q - p \cdot q$.} fuzzy interpretation both yield correct results, the latter incorrectly overestimates probabilities in the general case, due to the semantics of disjunction. The neutral sum problem is the phenomenon arising when disjunction semantics does not satisfy idempotence (i.e., $\texttt{p} \vee \texttt{p} = \texttt{p}$ in a Boolean setting, but $p \oplus p \not = p$ in its numeric extension), the disjoint sum problem arises when disjunction semantics does not correspond to set union (i.e., $\texttt{p} \vee \texttt{q} \leq p \oplus q$, being exactly equal only if $\texttt{p}$ and $\texttt{q}$ are independent). These problems also arise when computations are performed in a different base (e.g., in log-probability space, or when using different t-norms in a fuzzy setting). 
Weighted Model Counting (WMC) is a general framework for probabilistic inference, which takes into account proper disjunction semantics, to avoid the neutral and disjoint sum problems. %computing probabilities \smc{in a more precise way}. 

Algebraic Model Counting (AMC)~\cite{kimmig2017algebraic} extends Weighted Model Counting by replacing Boolean operators with elements of an algebraic semiring, allowing to solve a plethora of probabilistic tasks within a single framework. Weighted Model Counting and Algebraic Model Counting are in general $\textsc{\#p-complete}$~\cite{chavira2008probabilistic}, however they become tractable when logic formulae possess a specific structure. Knowledge Compilation~\cite{darwiche2002knowledge} amortizes execution time by converting input formulae into equivalent target normal forms, on top of which clausal inference (and possibly other classes of tasks) can be executed in polynomial time. Different normal forms are characterized by trade-offs between size and efficiency, as well as their ability to address the neutral sum and disjoint sum problems. 
In this context, we mention sd-DNNF, the smooth and decomposable Deterministic Negated Normal Form, a popular Knowledge Compilation target language, which guarantees correct model counting in polynomial time, also in the presence of neutral and disjoint sums.

DeepProbLog~\cite{manhaeve2018deepproblog} is a Neural extension of the probabilistic logic programming language ProbLog~\cite{de2007problog}. In DeepProbLog Neural Predicates link together a probabilistic predicate $\texttt{p/k}$ with the output of a normalized Neural Network $\phi: \gX^k \mapsto [0, 1]$, in a back-propagable fashion, by means of Algebraic Model Counting over differentiable semirings.
Exact inference in DeepProbLog is expensive and often intractable, because the Knowledge Compilation and Algebraic Model Counting steps need to consider every proof, Scallop~\cite{li2023scallop} is an approximate inference framework based on DataLog, considering only the top-k proofs of the neuro-symbolic program, and exploiting provenance semirings~\cite{green2007provenance} to tune the tractability-accuracy trade-off.

\section{Distant Supervision}
Both Neuro-Symbolic systems based on probability~\cite{manhaeve2018deepproblog, winters2022deepstochlog} and those based on fuzzy logic~\cite{van2022analyzing} are routinely applied to Distant Supervision, which is an important and well-explored application of Neuro-Symbolic Artificial Intelligence. 
In a typical learning setting, a parametrized neural network $\phi_{\vtheta}: \sX \mapsto \sC$ maps instances from the input space $\sX$ to intermediate labels in a latent concept space $\sC$. A parameter-free symbolic and differentiable function $f: \sC^n \mapsto \sY$ is then used to compute a final label from the set $\sY$. During the learning process, neural network parameters $\vtheta$ (which affect outputs at the level of $\sC$) are updated by stochastic gradient descent, guided by supervision at the level of $\sY$. Given an annotated dataset $\gD \subseteq \sX \times \sY$,\footnote{This is different from Concept Bottleneck Models, where datasets are $\gD \subseteq \sX \times \sC \times \sY$.} the optimization objective in Distant Supervision~\cite{manhaeve2018deepproblog} can be formally expressed as:\footnote{Here we assume a single neural network $\phi_\vtheta$ applied to $\vx_1, \dots, \vx_n$ perceptual inputs, i.e., we are assuming a parameter sharing setting.}
$$
\vtheta^{*} = \mathop{\mathrm{argmax}}_{\vtheta} \sum_{\langle\vx, \vy\rangle \in \mathcal{D}} \llbracket f(\phi_{\vtheta}(\vx_{1}),\dots,\phi_{\vtheta}(\vx_{n})) = \vy \rrbracket.
$$
MNIST Addition~\cite{manhaeve2018deepproblog} and MNIST XOR~\cite{marconato2023not} are two popular benchmarks for Distant Supervision. In MNIST Addition, the input space $\sX = \left\{\mathimg{mnist0}, \mathimg{mnist1}, \dots, \mathimg{mnist9}\right\}$ corresponds to images from the MNIST Digits~\cite{lecun1998gradient} dataset, while the output label is an integer $\sY = [0, 19]$, corresponding to the sum of two intermediate labels $\sC = [0, 9]$. On the other hand, MNIST XOR is an apparently simpler task, in which images can only take values in $\sX = \left\{\mathimg{mnist0}, \mathimg{mnist1}\right\}$ and output labels are a boolean $\sY = \{0, 1\}$, corresponding to the exclusive-or of two intermediate labels $\sC = \{0, 1\}$.

Distant Supervision experiments on the two tasks, however, present radically different outcomes: while MNIST Addition is relatively easy to optimize, MNIST XOR is characterized by considerable optimization challenges.
These differences can be explained by observing the behavior of the symbolic function $f$. In neither case $f$ is an injection, therefore there are multiple possible inputs which can be mapped to the same output, and disambiguation relies entirely on observing data points in a meaningful way. 

A \textit{reasoning shortcut}~\cite{marconato2023not} is any spurious mapping of intermediate labels $\sC$ which, from the perspective of $f$, still produces valid output labels $\sY$. In MNIST Addition, reasoning shortcuts are present due to the fact that addition is a commutative operation, and the fact that multiple combinations yield the same sum (e.g., $\mathimg{mnist0} + \mathimg{mnist5} = \mathimg{mnist1} + \mathimg{mnist4} = \mathimg{mnist2} + \mathimg{mnist3} = 5$), however, when enough data is observed in an independent and identically-distributed fashion, the chance of learning an incorrect mapping function $\phi_\vtheta$ is relatively low.
Conversely, in MNIST XOR, the symbolic function $f$ yields correct results under two possible intermediate mappings ($\phi: \left\{\mathimg{mnist0} \mapsto 0, \mathimg{mnist1} \mapsto 1\right\}$, and $\phi: \left\{\mathimg{mnist0} \mapsto 1, \mathimg{mnist1} \mapsto 0\right\}$), because the function is commutative and symmetric with respect to labels ($f(0,0) = f(1,1), f(0,1) = f(1,0)$). In this scenario, there is an equal chance for the optimizer to learn either the correct or the incorrect mapping, unless some prior hypothesis on the labeling of $\sC$ can be injected (e.g., by means of a shallow supervised pre-training).

Reasoning shortcuts are not entirely dependent on the nature of the symbolic mapping $f$, and data distribution plays an equally important role.
MNAdd-Shortcut~\cite{marconato2023neuro} is a  non-i.i.d. variation of MNIST Addition, where all the samples containing couples of even digits are observed before any sample containing couples of odd digits (and mixed odd-even couples are never observed). This simple modification in sampling increases dramatically the likelihood of learning reasoning shortcuts, instead of the intended mapping function.

\section{Neuro-symbolic Temporal Reasoning}
Exploiting background temporal knowledge is a popular approach in Reinforcement Learning, where safety and composability requirements naturally emerge. In this domain, Linear Temporal Logic is a popular choice for knowledge specification, as it acts as a concise formalism describing the temporal behavior of ``good'' sequences, with syntactical restrictions verifiable in finite time-steps, also on infinite traces~\cite{lacerda2015optimal}.
%
Approaches enforcing safety requirements may employ Reward Shaping to penalize violations of the temporal specification~\cite{camacho2017non,umili2024neural,bagatella2024directed,camacho2019ltl,jiang2021temporal}, or exploit the equivalence between \LTL formulae and finite state machines, to encode the policy directly as a product Markov Decision Process~\cite{fu2014probably,wen2015correct}, consisting of two modules, the encoded formula, and a learned component. A different take on the same idea is to encode the \LTL formula directly as a module of the neural architecture, providing also the benefits of end-to-end differentiability. In this direction, \LTL formulae may be encoded as Recurrent Neural  Networks~\cite{kuo2020encoding}, or  Graph Neural Networks~\cite{vaezipoor2021ltl2action}.
Another approach to Safe Reinforcement Learning is Shielding~\cite{alshiekh2018safe}, where the output action of an unrestricted policy is modified by a symbolic component, in the case of a violation of the temporal specification.

Task composition can be modeled as language intersection, union or concatenation, by exploiting \LTL equivalence with ($\omega$-)regular languages, thus enabling a divide-and-conquer approach to Reinforcement Learning. In this category, approaches include learning a recursive composition function on top of low-level skill embeddings~\cite{sahni2017learning}, encoding multi-task reinforcement learning as collections of \LTL properties~\cite{toro2018teaching}, and learning a collection of minimum-violation task primitive policies which act as a library composed at inference time with Boolean operators~\cite{bergeron2024temporal}.

Neuro-symbolic temporal reasoning tasks include: Temporal Formula Induction, Approximate Satisfiability and Sequence Classification driven by background knowledge.
%\footnote{\sm{Approximate satisfiability (with neural networks) and knowledge-driven sequence classification are related, as, in some circumstances, the former can be seen as a restriction of the latter, using symbolic inputs (instead of more general perceptual features grounded into symbols) and the set of learnable targets corresponding exactly to the content of the background knowledge (whereby sequence classification can, in general, be learned with incomplete knowledge or, as in the case of this paper, after additional, non-temporal, reasoning steps).}}
Camacho et al.~\cite{camacho2019learning} address Formula Induction in a symbolic fashion, by building a vocabulary of sub-formulae which are converted to Alternating Finite-state Automata, and then composed to discover the target formula from positive and negative examples, while Walke et al.~\cite{walke2021learning} propose the use of specialized recurrent layers for Sequence Classification, which can collectively be interpreted as an \LTLf formula, by extracting a truth table from discretized weights.
Finally, Umili et al.~\cite{umili2024deepdfa} attempt to learn Deterministic Finite-state Automata (DFA) transition matrices from examples, by discretizing a Recurrent Neural Network, regularized during training by enforcing one-hot hidden representations and temperature-scaled softmax annealed over time
to produce discrete activations.

Exact \LTL Satisfiability is $\textsc{pspace-complete}$. However, several approaches based on Neural Networks have been proposed to approximate Satisfiability in polynomial time. Xie et al.~\cite{xie2021embedding} employ Message Passing Graph Neural Networks to learn embeddings for a Deterministic Finite-state Automaton equivalent to the target \LTLf formula, via a Triplet Loss comparing satisfiable and unsatisfiable traces.
Similarly, Mukherjee et al.~\cite{mukherjee2022octal} exploit Graph Isomorphism Networks to perform approximate model checking~\cite{clarke2018introduction}; %(i.e., the task of determining whether a provided labeled transition system satisfies a temporal specification) by embedding both the query non-deterministic B\"uchi automaton and the syntax tree of the target \LTL formula into two graphs, which are then merged to compute a single embedding, which is finally classified.
Luo et al.~\cite{luo2022checking,luo2024learning} use Recursive Neural Networks~\cite{socher2012semantic} to generate explanations as traces satisfying the given formulae. 
%Luo et al. propose multiple approaches to \LTL and \LTLf satisfiability by means of neural networks, with a specific focus on computation speed. In~\cite{luo2022checking} they propose the use of TreeNN~\cite{socher2013recursive} to embed the formula's syntax tree, in~\cite{luo2023sat} they extend their approach to one-step unfolded graphs, where syntactic features (the syntax tree) are augmented by semantic ones, corresponding to propositions which must hold either in the current state or the immediately successive one in the trace, allowing also to employ the trained graph neural network to generate explanations as traces satisfying the formula, and in~\cite{luo2024learning} they propose neural trace checking as framework for approximate \LTL trace checking (i.e., sequence classification with \LTL knowledge) and trace generation, achieving large speed-ups compared to exact symbolic methods.

Yan et al.~\cite{yan2022neuro} propose a two-step approach to multi-class Time-series Classification, exploiting Signal Temporal Logic (a continuous extension of \LTL) to train an interpretable Neural Network, over augmented inputs, consisting of raw, spectral and derivative features. Truth values are relaxed by quantitative satisfaction functions, allowing single output neurons to be interpreted as (weighted) sub-formulae, each trained by Binary Cross-entropy. In the second, non-differentiable, step, a decision tree-inspired algorithm combines the output of multiple neurons in a complete formula. 

\paragraph{Neuro-Symbolic Automata.}

%Since trace acceptance in finite state automata is performed by following a transition matrix to recursively update the automaton state,
There is a strong link between inference in Deterministic Finite-state Automata and Recurrent Neural Networks, as the former checks trace acceptance using a state transition matrix and the latter updates an internal state according to a (learned) deterministic function.
%
Additionally, the discrete nature of Deterministic Finite-state Automata is particularly amenable to be encoded by (sets of) Boolean formulae, which can be subject to Neuro-symbolic integration.
%
Umili et al.~\cite{umili2023grounding} exploit background knowledge in the form of \LTLf formulae to learn symbolic labels, by performing Distant Supervision across sequences.
In their framework, the \LTLf formula is converted to a Deterministic Finite-state Automaton, using a an off-the-shelf compiler, the resulting transition matrix is converted into a disjunction of Horn clauses, %in the form $\text{next state} \leftarrow \text{previous state} \wedge \text{transition guard}$.
and the entire logic program is finally encoded into a Logic Tensor Network
%, using a product t-norm ($a \wedge b = a \cdot b, a \vee b = a + b - a \cdot b$), which is recursively unfolded, as the input sequence is traversed.
that can be trained end-to-end on sequence labels, by means of Binary Cross-entropy or a proposed Semantic Loss penalizing discordance between ground truth labels and the observed final state. % which penalizes every time the final state is discordant with the ground truth label (details in Appendix~\ref{ijcai:app:main}).
In spite of not receiving any symbol-level supervision, they successfully retrieve correct labels for both existing and novel automata-based benchmarks where symbols are replaced by synthetic images.
%
Motivated by training instabilities and a general failure to address sequence classification in more complex datasets and temporal specifications, Manginas et al.~\cite{manginas2024nesya} replace the fuzzy encoding with a probabilistic one. Each transition guard is compiled into an sd-DNNF, and the automaton is given probabilistic semantics, by means of Algebraic Model Counting, largely improving performance, convergence and scalability.
%($a \wedge b = a \cdot b, a \vee b = a + b$), achieving higher performance and better convergence during training, especially in automata affected by the neutral and disjoint sum problems. Their approach is also significantly more scalable, thanks to an highly parallelizable matrix factorization of the resulting sum-product network.
Umili et al. and Manginas et al. works are both framed within a propositional setting, as they rely on Deterministic Finite-state Automata. Symbolic Finite-state Automata~\cite{veanes2010symbolic,veanes2013applications,d2017power} extend Deterministic Finite-state Automata to infinite alphabets, enabling inference in a relational framework, at the expenses of additional challenges.