\chapter{The Challenge of Learning Symbolic Representations}
\label{chap:chalsymb}

In this chapter we cover Symbolic Representation Learning, enumerating the desirable properties a symbolic system should possess, and the challenges existing and novel frameworks must address. The content of this chapter is adapted from our NeSy2023~\cite{lorello2023challenge} paper.


\section{Symbolic Representations}
In their everyday activities, humans continuously operate with symbols. Reasoning skills, decision making processes, planning activities, causality modeling, all require symbol formalization and manipulation. AI systems designed to address these tasks typically do not require to also learn the symbolic representations they operate on: symbols, predicates, or concepts are usually known a priori, or given by an external source of information, such as a supervisor~\cite{ciravegna2023logic}.
%
According to Newell and Simon~\cite{newell1972human}, a symbolic system maps abstract entities into symbols that are (i.) \textit{arbitrary} (i.e., whose shapes have no relation with their semantic meaning) and (ii.) \textit{recursively composable} (to produce complex and more general representations from elementary entities). In order to guarantee both properties, a symbol must belong to a discrete set.
%
For an effective representation of a given collection of concepts,  symbols should also be (iii.) \textit{non-ambiguous}, meaning that different symbols represent different concepts~\cite{asai2018classical}, and (iv.) \textit{pure}, suggesting that a concept should be encoded by the lowest possible number of symbols~\cite{chen2020concept}.
%
Learning these symbolic representations from perceptual stimuli is a challenging task. In fact, there exist several works that try to learn discrete representations, like Discrete Probabilistic Latent Spaces~\cite{asai2018classical}, Vector-quantized Variational Auto-encoders~\cite{van2017neural}, or Deep Hashing methods~\cite{luo2020survey}. All these approaches focus on downstream performance, neglecting the properties which make a symbolic representation a good one.
Building a differentiable end-to-end approach for discrete, symbolic, representations poses a number of challenges, starting from the ill-defined nature of gradient-based techniques~\cite{poganvcic2020differentiation}.
%
Ideally, the learning process that produces symbolic representations should be (v.) \textit{unsupervised}, or at least weakly/partially supervised~\cite{stammer2022interactive}. This observation raises additional issues that suggest to re-think the whole learning paradigm, advocating the need for novel evaluation methods, addressing the effectiveness of the learned representations.
%
Symbolic manipulation is almost unanimously assumed to play an important role in reasoning generalization. The Binding Problem~\cite{greff2020binding} for sub-symbolic systems is an open problem concerning the generation and manipulation of symbolic entities (objects) starting from sub-symbolic stimuli. Many Neuro-symbolic approaches address this problem, by combining symbolic and sub-symbolic components, so that manipulation sub-tasks (notoriously difficult to address by Neural Networks) are dealt by the former whereas learning and noise-sensitive sub-tasks (difficult to address symbolically) are solved by the latter.
%
There is extensive literature in Philosophy of Science concerned with the formal definition of desirable properties for symbols and symbolic reasoning.
%
In the work by Taddeo and Floridi~\cite{taddeo2005solving}, for example, a ``truly'' symbolic system has to perform grounding while satisfying the \textit{Zero Semantic Commitment Condition} (i.e., the agent must be able to develop its own semantics without external guidance). In the work by Santoro et al.~\cite{santoro2021symbolic}, properties are instead defined within a Meaning-by-convention framework: symbolic behavior is defined as the set of traits allowing an interpreter to operate within a socio-cultural setting. They identify six desirable properties, possessed by human behavior but not yet by autonomous agents, and postulate that symbolic fluency can arise as emergent behavior under Meaning-by-convention training regimes, exploiting social interactions with humans, mediated by natural language, and large training sets. According to them, symbolic systems should be: \textit{receptive}, \textit{constructive}, \textit{embedded}, \textit{malleable}, \textit{meaningful} and \textit{graded}. While these properties are certainly intuitive, they are difficult to quantify and, therefore, they cannot be exploited to guide the learning process.

\section{Properties of Symbolic Representations}
\label{nesy2023:sec:psr}

To be beneficial in a computational context, symbolic representations should possess the following desirable properties: (i.) \textit{non-ambiguity}, (ii.) \textit{purity}, (iii.) \textit{usefulness}, (iv.) \textit{symbol composability}, (v.) \textit{manipulation composability}, and (vi.) \textit{generalizability} with respect to different tasks.
Other desirable, but possibly application-specific, properties are: (vii.) \textit{compactness}, (viii.) \textit{monotonicity}, and (ix.) \textit{invertibility} (or de-composability).

\paragraph{Non-ambiguity and Purity.} \textit{Non-ambiguity} means that different entities should not be mapped to the same representation, while \textit{purity} is its dual: every entity should have the smallest possible number of representations (ideally only one each). A high degree of non-ambiguity increases downstream performance and a high degree of purity implies a stronger robustness to noise. If both properties are optimal, there is a 1-to-1 mapping between entities and their representations.

\paragraph{Usefulness.} \textit{Usefulness} is the capability of improving performance for a downstream symbolic task, with respect to another representation. According to Newell and Simon~\cite{newell1972human}, a symbolic system should be able to operate with arbitrary symbols. However, this property only works under ideal assumptions of perfect non-ambiguity and purity, whereas imperfect representations may convey information more or less effectively. Moreover, an arbitrary representation does not allow to optimize for performance, preventing the use of heuristics or pruning strategies.
We advocate for a case-by-case evaluation of usefulness, as tasks with a large reasoning component will arguably benefit more from a concise representation, while tasks pivoting around a strong perceptual component may benefit more from redundant representations, robust to noise. It is also important to note that usefulness is necessarily a relative metric, subject to how the representation is used (e.g., a random projection processed by a powerful black-box may be more useful than a semantically-meaningful concept bottleneck processed by a linear layer). %a small usefulness with respect to a large performance may be more beneficial than a great usefulness associated with low performance.

\paragraph{Symbol Composability.} \textit{Symbol composability} is the possibility of creating complex constructs (e.g., sequences, expressions, graphs, etc.) from atomic symbols and it is commonly accepted as the key component of any form of reasoning. As both perceptual information and underlying semantics are seldom ``flat'', it is often necessary to encode hierarchies of entities. Grounding complex structures can be addressed by a wide spectrum of strategies, ranging from grounding atoms into a fixed structure, to learning part-whole hierarchies from perceptual stimuli~\cite{greff2020binding}. Since different downstream tasks require different abstractions, we advocate for a semi-quantitative evaluation of symbol composability, to determine whether a given technique is beneficial, while acknowledging the difficulty in devising a quantitative metric.

\paragraph{Manipulation Composability.} \textit{Manipulation composability} is the capability of deriving a new symbol by performing a sequence of operations on top of an existing one. There are many reasons justifying the need of manipulating entitites in a learnable way. To give some examples: 
the initial encoding may be at the ``wrong'' abstraction level (thus requiring a specialization/generalization operation), there may be the need to enforce a specific property (e.g., when encoding the set of natural numbers, it can be beneficial to enforce that each number is the successor of some other number), incremental construction (like contextual embeddings are computed in a Transformer), denoising a representation, and so on.
Although distinct concepts, manipulation composability is strongly related with the principle of \textit{elaboration tolerance}~\cite{mccarthy1998elaboration} in Knowledge Representation, as it provides a mechanism to alter (or, conversely, guarantee invariance) a representation in response to external conditioning. As manipulation composability paves the way for recursive processing, it also provides enough expressive power to allow a certain degree of reasoning capability, thus, just like symbol composability, it is important to quantify such capability.
Although useful from a practical perspective, because it decomposes a complex transformation into a sequence of simpler ones, it can also provide the basis for secondary properties, such as monotonicity, commutativity of transformations, emergent periodicity, presence of kernel representations, etc.

\paragraph{Generalizability.} \textit{Generalizability} is the capability of reusing the same representations for different downstream tasks, paving the way for more efficient training, multi-task learning, the discovery of shared structure, et cetera.
An arbitrary representation is also trivially general, however it also negates all the advantages of a general representation.

\paragraph{Other Properties.} Among other desirable properties, the size of a \textit{compact representation} approaches the Shannon limit for the distribution of entities it encodes (useful for every downstream task, but especially important for those in \textsc{EXPTIME} or above), a \textit{monotone} representation allows to define an ordering between representations mirroring an ordering between entities (this is particularly useful for applications involving temporal steps, sequences, counting objects, etc.), and an \textit{invertible} representation can allow to undo a manipulation to retrieve an input symbol from an output (useful for example in the case of deduction, backward planning, diffusion processes, etc.).

\section{Symbolic Representation Learning}\label{nesy2023:sec:related}
Neural discrete representations have been successfully used for a plethora of tasks.
%
Embedding tables encode a finite (and thus discrete) set of objects with a continuous representation, therefore, using signal processing terminology, they should be more correctly identified as ``sampled'' approaches. 
Vector-quantized Variational Auto-encoders (VQ-VAEs)~\cite{van2017neural} exploit a quantized embedding table, effectively making the representations discrete. Such representations avoid posterior collapse, achieving outstanding results in image and sound generation tasks.
In the domain of Diffusion Models, Post-training Quantization approaches, such as Q-Diffusion~\cite{li2023q}, often play an important role in model compression and inference acceleration.
SD-$\pi$XL~\cite{binninger2024sd} is a Diffusion Model capable of producing discrete output images (useful for artistic applications such as pixel art, but also manufacturing applications such as embroidery and brick design), by combining Semantic Loss, Distillation Sampling and Gumbel re-parametrization trick.
The categorical re-parametrization trick (Gumbel-softmax operator)~\cite{jang2016categorical} and its variant, the concrete distribution (Gumbel-sigmoid operator)~\cite{maddison2016concrete}, are continuous relaxations of categorical and binary random variables, respectively. These methods exploit the Gumbel re-parametrization trick, typical of Variational Auto-encoders, to split a random variable into a differentiable deterministic component and random noise.
Discretization is achieved by annealing a temperature parameter to zero, and it is thus susceptible to a trade-off between the ``discreteness'' of the representation and the ``informativeness'' of its gradient. This trade-off is often mitigated by means of an annealing schedule during learning or a straight-through estimation strategy (e.g., passing the argmax during the forward pass and the annealed softmax during the backward pass), however these approaches remain particularly brittle and extremely sensitive to the choice of hyperparameters, because they introduce a bias in the estimation of gradients.
The REINFORCE~\cite{williams1992simple} framework is capable of producing unbiased gradients, at the expenses of high variance and an inefficient sampling procedure.
The CatLog-Derivative trick~\cite{de2023differentiable} addresses both issues of biased gradient estimation and high variance, allowing to differentiate through categorical distributions.
%
Deep Hashing methods~\cite{luo2020survey} deal with efficient information retrieval, exploiting binary latent representations which are then used to address buckets by means of Hamming distance. Research directions in this area mainly focus on non-differentiability issues of discrete representations and the Hamming function, as well as efficiency, in terms of number of training samples, availability of annotations and retrieval performance.
%
Among Neuro-symbolic approaches, methods feeding Combinatorial Optimizers with neural information must deal with discrete representations and how to back-propagate through ill-defined gradients.
A plethora of solutions~\cite{agrawal2019differentiable,poganvcic2020differentiation,fredrikson2023learning,wang2019satnet} have been proposed to define a gradient which is both well-behaved and useful as a learning signal which allows to exploit information from the downstream task of Combinatorial Optimization. These techniques however are often method-specific and are difficult to generalize to other tasks (e.g., planning or deduction).

\subsection{Challenges of Symbolic Representation Learning}
\label{nesy2023:sec:cl}
The challenges related to the problem of learning symbolic representation, are strongly coupled with the necessity of guaranteeing adherence to some, or all, of the desirable properties highlighted so far.
It is not possible to provide a ready-to-use methodology, as each instance is unique and heavily dependent on application domain and chosen implementation. However, there exist some common challenges characterizing symbolic representation learning: (i.) \textit{differentiability} through discrete bottlenecks, (ii.) \textit{approximation errors} when using continuous relaxations, (iii.) \textit{limited knowledge availability}, (iv.) \textit{evaluating representation goodness}.

\paragraph{Differentiating Through Discrete Bottlenecks.}
Discretization can be modeled by the application of some step function to a continuous input,\footnote{Classical examples are the sign, floor and ceil functions.} which is characterized by a meaningless gradient (zero everywhere, except at discontinuities).
Information flow is effectively stopped, when learning relies on gradient-based optimization, as the chain rule will propagate zeroes every time a step function is composed to any other function.
%
Existing methods mitigating this issue are not general and introduce additional problems.
Residual connections between continuous and discrete representations are a naive and somewhat ineffective approach: since gradient only flows along the continuous path, the learning process is encouraged to discard information coming from the discrete one.
A temperature parameter scaling inputs for a sigmoid or softmax non-linearity can be annealed to zero during training, providing a progressively smaller gradient. Although simple and potentially effective, this method is sensitive to initial values and annealing schedule~\cite{kaiser2018discrete}.
Straight-through estimation replaces a non-differentiable non-linear activation with the identity function in the backward pass, hence ``skipping'' the activation during chain rule computation. This approach works well in those cases in which the non-linearity closely approximates the identity,
%(e.g., $sign(x)$, provided that input values do not lie far from zero),
but may provide misleading gradient updates when this assumption does not hold.
Methods such as the ones exploited by differentiable combinatorial optimizers~\cite{fredrikson2023learning} are extremely powerful techniques for back-propagation, based on building gradients as finite differences between the input representation and the minimal perturbation acting as a counterfactual. Although effective and representation-centric, they require binary decision boundaries and are slow to compute.

\paragraph{Approximation Error in Relaxed Representations.}
Optimizing discrete representations through continuous loss functions pose additional challenges, due to highly non-convex landscapes. 
%
Similarly, symbolic computations are usually composed of non-differentiable steps, and therefore it may be challenging to devise both a quantitative evaluation of the representation, and an optimizable continuous relaxation or upper bound of the learning objective.
%
Assignment-based manipulations (e.g., deduction, Hungarian matching, etc.) can be reformulated within a fuzzy or probabilistic framework, allowing for a differentiable objective, with suitable thresholding operations performed at inference time, which can however present boundary instability issues.
%
Retrieval-based approaches heavily rely on non-differentiable functions comparing different representations (such as the Hamming distance) and often require to devise a continuous upper bound~\cite{norouzi2012hamming}.

\paragraph{Limited Knowledge Availability.}
High-quality training data is often expensive to annotate and the ideal condition in which supervision is provided for every concept associated to each data point may be unachievable in real-world applications. 
Symbolic Representation Learning should exploit intrinsic characteristics which reduce the quantity and quality of annotations required, ideally up to the completely unsupervised discovery of symbols and their compositions. 
In general, one could provide (i.) \textit{complete supervision} on concepts, (ii.) \textit{supervision on the downstream task} only, (iii.) \textit{no supervision} at all, (iv.) \textit{weak or partial supervision} in the form of relations between entities (e.g., monotonicity constraints, ontologies, equivalence classes between entities, etc.).
%
Knowledge plays an important role both in learning and reasoning. Being able to learn a representation by means of knowledge injection is not only a way of reducing the amount of data required to achieve a ``good'' representation, but also greatly improves its usefulness.
%
Knowledge can be injected in the form of (i.) \textit{representational constraints} (e.g.,
%the representation of ordered objects should be monotonic, or 
distances between representations should mirror paths inside a knowledge graph), (ii.) \textit{constraints related to the downstream task structure} (e.g., as it happens with classical planning~\cite{asai2018classical}), (iii.) \textit{manipulation constraints} (e.g., symbols should be combined according to a generative grammar).

\paragraph{Evaluating Representation Quality.} Regarding evaluation metrics for symbolic representations, we do not believe in the existence of a one-size-fits-all collection of metrics, in virtue of different downstream applications, for which different subsets of desirable properties are needed. 
In order to design a suitable metric, one should consider: (i.) the \textit{target property}, (ii.) the \textit{type of supervision} required, (iii.) the \textit{interaction with learning}.
%
Differentiable metrics may be also exploited during learning. Along this dimension we can distinguish (i.) \textit{truly differentiable metrics}, (ii.) \textit{non-differentiable metrics}, (iii.) metrics with \textit{differentiable proxies} (e.g., Hamming distance approximated by binary cross-entropy), (iv.) \textit{compliance to logic or combinatorial constraints}.
In the latter case it may be possible to define, for example, complex purity measures taking into account hierarchies of entities, or logic formulae against which compliance can be evaluated with techniques such as Semantic-based Regularization.

